{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETR Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exouser/Downloads/my_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-15 13:15:09.963532: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734268509.981451  382692 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734268509.986930  382692 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-15 13:15:10.007979: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import time  # For measuring time\n",
    "\n",
    "# Third-party imports\n",
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PIL (Python Imaging Library)\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# torchvision imports\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Transformers imports\n",
    "from transformers import DetrForObjectDetection, DetrConfig, DetrImageProcessor\n",
    "\n",
    "# pycocotools imports\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "# timm (PyTorch Image Models) import\n",
    "import timm\n",
    "\n",
    "# Collections\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.76s)\n",
      "creating index...\n",
      "index created!\n",
      "Total images in the dataset: 29800\n",
      "Keys in the COCO annotations: ['info', 'licenses', 'categories', 'images', 'annotations']\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "data_folder = \"Self Driving Car/export/\"\n",
    "annotation_file = os.path.join(data_folder, \"_annotations.coco.json\")\n",
    "\n",
    "# Load COCO Annotations\n",
    "coco = COCO(annotation_file)\n",
    "\n",
    "# Print dataset statistics\n",
    "total_images = len(coco.getImgIds())\n",
    "print(f\"Total images in the dataset: {total_images}\")\n",
    "print(\"Keys in the COCO annotations:\", list(coco.dataset.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Inspect the annotation file to make sure it is suitable fro DETR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Keys in the COCO annotations: ['info', 'licenses', 'categories', 'images', 'annotations']\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Total images in the dataset: 29800\n",
      "Total annotations in the dataset: 194539\n",
      "Total categories in the dataset: 12\n",
      "Categories: ['obstacles', 'biker', 'car', 'pedestrian', 'trafficLight', 'trafficLight-Green', 'trafficLight-GreenLeft', 'trafficLight-Red', 'trafficLight-RedLeft', 'trafficLight-Yellow', 'trafficLight-YellowLeft', 'truck']\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Max classes per image: 7\n",
      "Min classes per image: 0\n",
      "Average classes per image: 1.88\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Sample image entry:\n",
      "{'id': 0, 'license': 1, 'file_name': '1478897026627294725_jpg.rf.6828a4e821cbab4c2c277d74df291f00.jpg', 'height': 512, 'width': 512, 'date_captured': '2021-06-09T12:24:25+00:00'}\n",
      "Sample annotation entry:\n",
      "{'id': 0, 'image_id': 0, 'category_id': 2, 'bbox': [140, 262, 21, 25.5], 'area': 535.5, 'segmentation': [], 'iscrowd': 0}\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (\"--------------------------------------------------------\")\n",
    "# Check the structure of the JSON file\n",
    "print(\"Keys in the COCO annotations:\", list(coco.dataset.keys()))\n",
    "\n",
    "print (\"--------------------------------------------------------\")\n",
    "print (\"--------------------------------------------------------\")\n",
    "# Total number of images\n",
    "num_images = len(coco.getImgIds())\n",
    "print(f\"Total images in the dataset: {num_images}\")\n",
    "\n",
    "# Total number of annotations\n",
    "num_annotations = len(coco.getAnnIds())\n",
    "print(f\"Total annotations in the dataset: {num_annotations}\")\n",
    "\n",
    "# Total number of categories\n",
    "num_categories = len(coco.getCatIds())\n",
    "print(f\"Total categories in the dataset: {num_categories}\")\n",
    "\n",
    "# List all categories\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "print(\"Categories:\", [cat['name'] for cat in categories])\n",
    "\n",
    "print (\"--------------------------------------------------------\")\n",
    "print (\"--------------------------------------------------------\")\n",
    "\n",
    "# Map image IDs to annotations\n",
    "img_to_anns = defaultdict(list)\n",
    "for ann in coco.loadAnns(coco.getAnnIds()):\n",
    "    img_to_anns[ann['image_id']].append(ann['category_id'])\n",
    "\n",
    "# Calculate the number of unique classes per image\n",
    "classes_per_image = [len(set(img_to_anns[img_id])) for img_id in coco.getImgIds()]\n",
    "\n",
    "# Statistics\n",
    "max_classes = max(classes_per_image)\n",
    "min_classes = min(classes_per_image)\n",
    "avg_classes = np.mean(classes_per_image)\n",
    "\n",
    "print(f\"Max classes per image: {max_classes}\")\n",
    "print(f\"Min classes per image: {min_classes}\")\n",
    "print(f\"Average classes per image: {avg_classes:.2f}\")\n",
    "\n",
    "print (\"--------------------------------------------------------\")\n",
    "print (\"--------------------------------------------------------\")\n",
    "# Example image entry\n",
    "sample_image_id = coco.getImgIds()[0]\n",
    "sample_image = coco.loadImgs(sample_image_id)[0]\n",
    "print(\"Sample image entry:\")\n",
    "print(sample_image)\n",
    "\n",
    "# Example annotation\n",
    "sample_ann_id = coco.getAnnIds(imgIds=sample_image_id)[0]\n",
    "sample_annotation = coco.loadAnns(sample_ann_id)[0]\n",
    "print(\"Sample annotation entry:\")\n",
    "print(sample_annotation)\n",
    "\n",
    "\n",
    "print (\"--------------------------------------------------------\")\n",
    "print (\"--------------------------------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 25330, Validation images: 2235, Testing images: 2235\n"
     ]
    }
   ],
   "source": [
    "# Dataset splits\n",
    "num_train = 25330\n",
    "num_val = 2235\n",
    "num_test = 2235\n",
    "\n",
    "# Shuffle and split the dataset\n",
    "all_image_ids = coco.getImgIds()\n",
    "random.seed(42)  # Ensure reproducibility\n",
    "random.shuffle(all_image_ids)\n",
    "\n",
    "train_ids = all_image_ids[:num_train]\n",
    "val_ids = all_image_ids[num_train:num_train + num_val]\n",
    "test_ids = all_image_ids[num_train + num_val:num_train + num_val + num_test]\n",
    "\n",
    "print(f\"Training images: {len(train_ids)}, Validation images: {len(val_ids)}, Testing images: {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom COCO dataset\n",
    "class COCODataset(Dataset):\n",
    "    def __init__(self, image_dir, coco, processor, image_ids):\n",
    "        self.image_dir = image_dir\n",
    "        self.coco = coco\n",
    "        self.processor = processor\n",
    "        self.image_ids = image_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        image_path = os.path.join(self.image_dir, image_info[\"file_name\"])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Get annotations\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_id)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "        annotations = []\n",
    "\n",
    "        for ann in anns:\n",
    "            bbox = ann[\"bbox\"]  # [x_min, y_min, width, height]\n",
    "            area = bbox[2] * bbox[3]  # width * height\n",
    "            annotations.append({\n",
    "                \"bbox\": bbox,\n",
    "                \"category_id\": ann[\"category_id\"],  # Preserve original category IDs\n",
    "                \"area\": area,\n",
    "                \"iscrowd\": ann.get(\"iscrowd\", 0),\n",
    "            })\n",
    "\n",
    "        # Prepare the target dictionary\n",
    "        target = {\"image_id\": image_id, \"annotations\": annotations}\n",
    "\n",
    "        # Process the image and annotations\n",
    "        encoding = self.processor(images=image, annotations=target, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze(0)\n",
    "        labels = encoding[\"labels\"][0]\n",
    "        return pixel_values, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets prepared: 25330 training, 2235 validation, 2235 testing.\n"
     ]
    }
   ],
   "source": [
    "# Path to images\n",
    "image_dir = data_folder\n",
    "\n",
    "# Load pre-trained processor\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "\n",
    "# Create datasets for each split\n",
    "train_dataset = COCODataset(image_dir, coco, processor, train_ids)\n",
    "val_dataset = COCODataset(image_dir, coco, processor, val_ids)\n",
    "test_dataset = COCODataset(image_dir, coco, processor, test_ids)\n",
    "\n",
    "print(f\"Datasets prepared: {len(train_dataset)} training, {len(val_dataset)} validation, {len(test_dataset)} testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders ready.\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "print(\"DataLoaders ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel values shape: torch.Size([3, 800, 800])\n",
      "Target example: {'size': tensor([800, 800]), 'image_id': tensor([24621]), 'class_labels': tensor([2, 2, 2, 2, 2]), 'boxes': tensor([[0.4223, 0.4834, 0.0281, 0.0450],\n",
      "        [0.4980, 0.4851, 0.0312, 0.0483],\n",
      "        [0.5384, 0.4879, 0.0417, 0.0617],\n",
      "        [0.5366, 0.4854, 0.0302, 0.0333],\n",
      "        [0.6904, 0.5429, 0.1542, 0.1483]]), 'area': tensor([  810.0000,   966.6666,  1644.4445,   644.4445, 14635.5557]), 'iscrowd': tensor([0, 0, 0, 0, 0]), 'orig_size': tensor([512, 512])}\n"
     ]
    }
   ],
   "source": [
    "# Test a batch\n",
    "for pixel_values, targets in train_loader:\n",
    "    print(f\"Pixel values shape: {pixel_values[0].shape}\")\n",
    "    print(f\"Target example: {targets[0]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetrForObjectDetection(\n",
       "  (model): DetrModel(\n",
       "    (backbone): DetrConvModel(\n",
       "      (conv_encoder): DetrConvEncoder(\n",
       "        (model): FeatureListNet(\n",
       "          (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (bn1): DetrFrozenBatchNorm2d()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (layer1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer3): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (4): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (5): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer4): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (position_embedding): DetrSinePositionEmbedding()\n",
       "    )\n",
       "    (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (query_position_embeddings): Embedding(100, 256)\n",
       "    (encoder): DetrEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x DetrEncoderLayer(\n",
       "          (self_attn): DetrAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): DetrDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x DetrDecoderLayer(\n",
       "          (self_attn): DetrAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): DetrAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (class_labels_classifier): Linear(in_features=256, out_features=13, bias=True)\n",
       "  (bbox_predictor): DetrMLPPredictionHead(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model and processor\n",
    "model_path = \"DETR_BackboneTrained_30epochs/detr-finetuned\"\n",
    "processor_path = \"DETR_BackboneTrained_30epochs/detr-processor\"\n",
    "\n",
    "model = DetrForObjectDetection.from_pretrained(model_path)\n",
    "processor = DetrImageProcessor.from_pretrained(processor_path)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "## *FOR CALCULATING MEAN IOU OF TEST PREDICTIONS*\n",
    "\n",
    "def calculate_mean_iou(test_predictions, test_ground_truths):\n",
    "    all_ious = []\n",
    "    \n",
    "    for pred_sample, gt_sample in zip(test_predictions, test_ground_truths):\n",
    "        pred_boxes = pred_sample['boxes']\n",
    "        pred_scores = pred_sample['scores']\n",
    "        gt_boxes = gt_sample['boxes']\n",
    "        \n",
    "        if pred_boxes.size==0:  # Skip if no predictions\n",
    "            continue\n",
    "            \n",
    "        # Sort predictions by confidence score\n",
    "        pred_boxes_with_scores = sorted(zip(pred_boxes, pred_scores), \n",
    "                                      key=lambda x: x[1], \n",
    "                                      reverse=True)\n",
    "        pred_boxes = [box for box, _ in pred_boxes_with_scores]\n",
    "        \n",
    "        # Calculate best IoU for each ground truth box\n",
    "        for gt_box in gt_boxes:\n",
    "            ious = [calculate_iou(gt_box, pred_box) for pred_box in pred_boxes]\n",
    "            if ious:\n",
    "                max_iou = max(ious)\n",
    "                all_ious.append(max_iou)\n",
    "    \n",
    "    # Calculate mean IoU\n",
    "    mean_iou = sum(all_ious) / len(all_ious) if all_ious else 0.0\n",
    "    return mean_iou\n",
    "\n",
    "##*FOR CALCULATING MEAN IOU OF TEST PREDICTIONS PER CLASS*\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def calculate_mean_iou_per_class(test_predictions, test_ground_truths):\n",
    "    iou_per_class = defaultdict(list)\n",
    "    \n",
    "    for pred_sample, gt_sample in zip(test_predictions, test_ground_truths):\n",
    "        pred_boxes = pred_sample['boxes']\n",
    "        pred_labels = pred_sample['labels']\n",
    "        pred_scores = pred_sample['scores']\n",
    "        gt_boxes = gt_sample['boxes']\n",
    "        gt_labels = gt_sample['labels']\n",
    "        \n",
    "        # Group ground truth boxes by class\n",
    "        gt_boxes_by_class = defaultdict(list)\n",
    "        for gt_box, gt_label in zip(gt_boxes, gt_labels):\n",
    "            gt_boxes_by_class[gt_label].append(gt_box)\n",
    "            \n",
    "        # Group predicted boxes by class\n",
    "        pred_boxes_by_class = defaultdict(list)\n",
    "        for pred_box, pred_label, pred_score in zip(pred_boxes, pred_labels, pred_scores):\n",
    "            pred_boxes_by_class[pred_label].append((pred_box, pred_score))\n",
    "            \n",
    "        # Calculate IoU for each class\n",
    "        for class_id in gt_boxes_by_class.keys():\n",
    "            gt_boxes_class = gt_boxes_by_class[class_id]\n",
    "            pred_boxes_class = pred_boxes_by_class[class_id]\n",
    "            \n",
    "            if not pred_boxes_class:  # No predictions for this class\n",
    "                continue\n",
    "                \n",
    "            # Sort predictions by confidence score\n",
    "            pred_boxes_class = sorted(pred_boxes_class, key=lambda x: x[1], reverse=True)\n",
    "            pred_boxes_only = [box for box, _ in pred_boxes_class]\n",
    "            \n",
    "            # Calculate best IoU for each ground truth box\n",
    "            for gt_box in gt_boxes_class:\n",
    "                ious = [calculate_iou(gt_box, pred_box) for pred_box in pred_boxes_only]\n",
    "                if ious:\n",
    "                    max_iou = max(ious)\n",
    "                    iou_per_class[class_id].append(max_iou)\n",
    "    \n",
    "    # Calculate mean IoU for each class\n",
    "    mean_iou_per_class = {}\n",
    "    for class_id, ious in iou_per_class.items():\n",
    "        if ious:  # Only calculate mean if we have IoUs for this class\n",
    "            mean_iou_per_class[class_id] = sum(ious) / len(ious)\n",
    "        else:\n",
    "            mean_iou_per_class[class_id] = 0.0\n",
    "            \n",
    "    return mean_iou_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU with Libraries: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_mean_iou_with_libraries(predictions, ground_truths):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Intersection over Union (IoU) for a set of predictions and ground truths.\n",
    "\n",
    "    Args:\n",
    "        predictions (list of dict): List of dictionaries containing \"boxes\" (tensor) for predicted results.\n",
    "        ground_truths (list of dict): List of dictionaries containing \"boxes\" (tensor) for ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: The mean IoU across all predictions and ground truths.\n",
    "    \"\"\"\n",
    "    def calculate_iou(box1, box2):\n",
    "        \"\"\"\n",
    "        Calculate IoU for two sets of boxes using Torch's box utilities.\n",
    "\n",
    "        Args:\n",
    "            box1 (tensor): Ground truth box in the format [x_min, y_min, x_max, y_max].\n",
    "            box2 (tensor): Predicted box in the format [x_min, y_min, x_max, y_max].\n",
    "\n",
    "        Returns:\n",
    "            tensor: Tensor of IoU values.\n",
    "        \"\"\"\n",
    "        # Compute intersection\n",
    "        x1 = torch.max(box1[0], box2[0])\n",
    "        y1 = torch.max(box1[1], box2[1])\n",
    "        x2 = torch.min(box1[2], box2[2])\n",
    "        y2 = torch.min(box1[3], box2[3])\n",
    "\n",
    "        intersection = torch.clamp(x2 - x1, min=0) * torch.clamp(y2 - y1, min=0)\n",
    "\n",
    "        # Compute areas\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "        # Compute union\n",
    "        union = area1 + area2 - intersection\n",
    "\n",
    "        # Avoid division by zero\n",
    "        iou = intersection / union if union > 0 else torch.tensor(0.0)\n",
    "\n",
    "        return iou\n",
    "\n",
    "    all_ious = []\n",
    "\n",
    "    # Loop over predictions and ground truths\n",
    "    for pred_sample, gt_sample in zip(predictions, ground_truths):\n",
    "        pred_boxes = pred_sample[\"boxes\"]\n",
    "        gt_boxes = gt_sample[\"boxes\"]\n",
    "\n",
    "        if len(pred_boxes) == 0 or len(gt_boxes) == 0:\n",
    "            continue\n",
    "\n",
    "        # Match each ground truth box with the predicted boxes\n",
    "        for gt_box in gt_boxes:\n",
    "            ious = [calculate_iou(gt_box, pred_box) for pred_box in pred_boxes]\n",
    "            if ious:  # Append the highest IoU for this ground truth box\n",
    "                max_iou = max(ious)\n",
    "                all_ious.append(max_iou.item())\n",
    "\n",
    "    # Compute the mean IoU\n",
    "    mean_iou = sum(all_ious) / len(all_ious) if all_ious else 0.0\n",
    "    return mean_iou\n",
    "\n",
    "# Assuming `test_predictions` and `test_ground_truths` are prepared\n",
    "mean_iou = calculate_mean_iou_with_libraries(test_predictions, test_ground_truths)\n",
    "print(f\"Mean IoU with Libraries: {mean_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_env)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
